{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspi:  test\n",
    "\n",
    "- https://www.kaggle.com/code/hasibalmuzdadid/brain-stroke-analysis-accuracy-96-03/notebook#Basic-Exploration\n",
    "- https://www.kaggle.com/code/kaanboke/beginner-friendly-end-to-end-ml-project-enjoy\n",
    "- Emilies\n",
    "- Exercise 3 fra BDM – tager udgangspunkt i brain stroke datasæt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier\n",
    "\n",
    "*Source:* \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html?highlight=dummy+classifier#\n",
    "- Exercise 8\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Dummy Classifier model\n",
    "dummy_clf = DummyClassifier()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting y, the binary class label for stroke, for the test data.\n",
    "y_dummy_clf_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "accuracies = cross_val_score(estimator = dummy_clf, X = X_train, y = y_train, cv = 10)   \n",
    "\n",
    "# Reporting accuracy of the dummy classifier on the training and test set.\n",
    "print(\"---------- WITHOUT SMOTE ----------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dummy_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dummy_clf.score(X_test, y_test)))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (accuracies.mean(), accuracies.std())) # Printing the mean and standard deviation of the test scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** The dummy classifier is very accurate. This can be caused be the high imbalanced dataset, where only 5% of all instances are instances of stroke (y=1). Meaning that the dummy classifier would display high accuracy, although it always predicts \"No Stroke\" (y=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting confusion matrix using actual y_test and predicted y_test data sets \n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        y_dummy_clf_pred\n",
    "    ),\n",
    "    annot=True,\n",
    "    fmt = \"d\",\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"CONFUSION MATRIX: Dummy Classifier - Baseline Model (wo. SMOTE)\",fontsize=14)\n",
    "ax.xaxis.set_ticklabels(['No stroke', 'Stroke']); \n",
    "ax.yaxis.set_ticklabels(['No stroke', 'Stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \"This indicates that the dummy classifier predicts y=0 every time while getting 95% accuracy due to the imbalanced target variable. We will inspect how the dummy classifier performs with the resampled balanced dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- WITH SMOTE ----------\n",
    "# Defining Dummy Classifier model with the resampled dataset\n",
    "dummy_clf_res = DummyClassifier()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "dummy_clf_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predicting y, the binary class label for stroke, for the test data.\n",
    "y_dummy_clf_pred_res = dummy_clf_res.predict(X_test)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "accuracies_res = cross_val_score(estimator = dummy_clf_res, X = X_train_res, y = y_train_res, cv = 10)   \n",
    "\n",
    "# Reporting accuracy of the dummy classifier on the training and test set.\n",
    "print(\"---------- WITH SMOTE ----------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dummy_clf_res.score(X_train_res, y_train_res)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dummy_clf_res.score(X_test, y_test)))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (accuracies_res.mean(), accuracies_res.std())) # Printing the mean and standard deviation of the test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting confusion matrix using actual y_test and predicted y_test data sets \n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        y_dummy_clf_pred_res\n",
    "    ),\n",
    "    annot=True,\n",
    "    fmt = \"d\",\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"CONFUSION MATRIX: Dummy Classifier - Baseline Model (w. SMOTE)\",fontsize=14)\n",
    "ax.xaxis.set_ticklabels(['No stroke', 'Stroke']); \n",
    "ax.yaxis.set_ticklabels(['No stroke', 'Stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** This score looks better and more realistic after using the balanced dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inital Model\n",
    "\n",
    "\n",
    "sources: \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- k-fold cross validation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "- https://www.kaggle.com/code/siddheshera/stroke-eda-smote-9-models-90-accuracy#Model-Selection-\n",
    "- Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building initial Classification Tree Model \n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Train - Fitting the model to training set\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "\n",
    "# Predict target values (y) for new data in test set\n",
    "y_dtree_pred = dtree.predict(X_test)\n",
    "\n",
    "# -- Classification report -- \n",
    "# K-Fold Cross-Validation\n",
    "accuracies = cross_val_score(estimator = dtree, X = X_train, y = y_train, cv = 10)   \n",
    "\n",
    "# Printing scores on training and testing \n",
    "print(\"---------- WITHOUT SMOTE ----------\")\n",
    "print(\"Accuracy-score on training data: {:.3f}\".format(dtree.score(X_train, y_train)))\n",
    "print(\"Accuracy-score on testing data: {:.3f}\".format(dtree.score(X_test, y_test)))\n",
    "print(\"K-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (accuracies.mean(), accuracies.std())) # Printing the mean and standard deviation of the test scores\n",
    "print('Precision-score: %.3f' % precision_score(y_test, y_dtree_pred))\n",
    "print('Recall-score: %.3f' % recall_score(y_test, y_dtree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test,y_dtree_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting confusion matrix using actual y_test and predicted y_test data sets \n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        y_dtree_pred\n",
    "    ),\n",
    "    annot=True,\n",
    "    fmt = \"d\",\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"CONFUSION MATRIX: Classification Tree - Initial model (wo. SMOTE)\",fontsize=14)\n",
    "ax.xaxis.set_ticklabels(['No stroke', 'Stroke']); \n",
    "ax.yaxis.set_ticklabels(['No stroke', 'Stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building initial Classification Tree Model \n",
    "dtree_res = DecisionTreeClassifier()\n",
    "\n",
    "# Train - Fitting the model to training set\n",
    "dtree_res = dtree_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict target values (y) for new data in test set\n",
    "y_dtree_pred_res = dtree_res.predict(X_test)\n",
    "\n",
    "# -- Classification report -- \n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "accuracies_res = cross_val_score(estimator = dtree_res, X = X_train_res, y = y_train_res, cv = 10)   \n",
    "\n",
    "# Printing scores on training and testing set\n",
    "print(\"---------- WITH SMOTE ----------\")\n",
    "print(\"Accuracy on training data {:.3f}\".format(dtree_res.score(X_train_res, y_train_res)))\n",
    "print(\"Accuracy  on testing data: {:.3f}\".format(dtree_res.score(X_test, y_test)))\n",
    "print(\"K-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies_res.mean()*100))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (accuracies_res.mean(), accuracies_res.std())) # Printing the mean and standard deviation of the test scores\n",
    "print('Precision-score: %.3f' % precision_score(y_test, y_dtree_pred_res))\n",
    "print('Recall-score: %.3f' % recall_score(y_test, y_dtree_pred_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test, y_dtree_pred_res, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting confusion matrix using actual y_test and predicted y_test data sets \n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        y_dtree_pred_res\n",
    "    ),\n",
    "    annot=True,\n",
    "    fmt = \"d\",\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"CONFUSION MATRIX: Classification Tree - Initial model (w. SMOTE)\",fontsize=14)\n",
    "ax.xaxis.set_ticklabels(['No stroke', 'Stroke']); \n",
    "ax.yaxis.set_ticklabels(['No stroke', 'Stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "- Training accuracy of 1.00 + bad accuracy on test data would indicatesoverfitting\n",
    "- We will tune hyperparameters and pruning the tree in order to avoid overfitting later on\n",
    "\n",
    "Exercise 5: \n",
    "K-cross validation socre - mean and standard deviation: \n",
    "The average test score is pretty bad, but more importantly, the standard deviation is quite big. Taken together, this tells us that the model is bad (low average test score), and the generalizability of the model unstable (high standard deviation). Sometimes the model might do okay, but sometimes it's horrible. Hence, this cross-validation tells us to expect the varying scores you might have noticed with your classmates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Decision Tree of our initial model\n",
    "\n",
    "# Remove comment - commented out to save computational power\n",
    "# --- WITHOUT SMOTE ---\n",
    "#plt.figure(figsize=(70,40))  # set plot size (denoted in inches)\n",
    "#tree.plot_tree(dtree,\n",
    "#               class_names=True,\n",
    "#               feature_names=list(X.columns), # label features with the column names from X\n",
    "#               filled=True, # color nodes to indicate majority class\n",
    "#               fontsize=10) \n",
    "# plt.show() # show \n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove comment - commented out to save computational power\n",
    "# --- WITH SMOTE ---\n",
    "#plt.figure(figsize=(70,40))  # set plot size (denoted in inches)\n",
    "#tree.plot_tree(dtree_res,\n",
    "#               class_names=True,\n",
    "#               feature_names=list(X_res.columns), # label features with the column names from X\n",
    "#               filled=True, # color nodes to indicate majority class\n",
    "#               fontsize=10) \n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing Hyperparameters - RandomizedSearchCV\n",
    "\n",
    "To avoid overfitting we will tune the model, by optimizing the hyperparameters using RandomizedSearchCV. \n",
    "\n",
    "Alternative method for optimizing hyperparameters:\n",
    "- Grid search (session 5)\n",
    "\n",
    "\n",
    "Sources:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "- https://medium.com/@senapati.dipak97/grid-search-vs-random-search-d34c92946318"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying RandomizedSearchCV for hyperparameter optimization\n",
    "# Declaring parameters to search through to use in the pipeline\n",
    "parameters = {'max_depth' : (5,6,7,8,10,20),\n",
    "              'max_features' : (1,2,4,5,6,7,8,10,15,20, None),\n",
    "              #'min_samples_leaf' : [1,2,3,4,5],\n",
    "              #'max_leaf_nodes' : [14,16,18,20,22],\n",
    "              #'min_samples_split' : [2,3,4,5],\n",
    "              'criterion' : ('gini', 'entropy')\n",
    "             }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing RandomizedSearchCV for the model\n",
    "dtree_tuned_pipeline = make_pipeline(StandardScaler(), \n",
    "                                    RandomizedSearchCV(DecisionTreeClassifier(), \n",
    "                                                       random_state = 5, param_distributions = parameters, \n",
    "                                                       cv = 5, verbose = True, scoring = 'recall'))\n",
    "\n",
    "# Fitting model to training set\n",
    "dtree_tuned = dtree_tuned_pipeline.fit(X_train,y_train)\n",
    "\n",
    "# Identifying the most optimal hyperparameters\n",
    "dtree_tuned[1].best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing RandomizedSearchCV for the model\n",
    "dtree_tuned_pipeline_res  = make_pipeline(StandardScaler(), \n",
    "                                       RandomizedSearchCV(DecisionTreeClassifier(), \n",
    "                                                          random_state = 5, param_distributions = parameters, \n",
    "                                                          cv = 5, verbose = True, scoring = 'recall'))\n",
    "\n",
    "# Fitting models to training set\n",
    "dtree_tuned_res = dtree_tuned_pipeline_res.fit(X_train_res,y_train_res)\n",
    "\n",
    "# Identifying the most optimal hyperparameters\n",
    "dtree_tuned_res[1].best_params_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning models\n",
    "The trained classification tree model is used to predict the outcome of the target variable y (Stroke 1 or 0) using the testing set\n",
    "TODO: Tjek model er opdateret med parametre"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning model with optimized hyperparameters\n",
    "#{'max_features': 15, 'max_depth': 10, 'criterion': 'gini'}\n",
    "dtree_tuned = DecisionTreeClassifier(max_features=15, \n",
    "                                   max_depth=10, \n",
    "                                   criterion='gini')\n",
    "\n",
    "# Train - Fitting model to training set \n",
    "dtree_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Predict y using test set\n",
    "y_dtree_pred = dtree_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test,y_dtree_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting confusion matrix using actual y_test and predicted y_test data sets \n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        y_dtree_pred\n",
    "    ),\n",
    "    annot=True,\n",
    "    fmt = \"d\",\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"CONFUSION MATRIX: Classification Tree - Tuned hyperparameters (wo. SMOTE)\",fontsize=14)\n",
    "ax.xaxis.set_ticklabels(['No stroke', 'Stroke']); \n",
    "ax.yaxis.set_ticklabels(['No stroke', 'Stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning model with optimized hyperparameters\n",
    "dtree_tuned_res = DecisionTreeClassifier(max_features=2, \n",
    "                                   max_depth=20, \n",
    "                                   criterion='gini')\n",
    "#{'max_features': 2, 'max_depth': 20, 'criterion': 'gini'}\n",
    "\n",
    "# Train - Fitting model to training set \n",
    "dtree_tuned_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict y using test set\n",
    "y_dtree_pred_res = dtree_tuned_res.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting confusion matrix using actual y_test and predicted y_test data sets \n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        y_dtree_pred_res\n",
    "    ),\n",
    "    annot=True,\n",
    "    fmt = \"d\",\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"CONFUSION MATRIX: Classification Tree - Tuned hyperparameters (w. SMOTE)\",fontsize=14)\n",
    "ax.xaxis.set_ticklabels(['No stroke', 'Stroke']); \n",
    "ax.yaxis.set_ticklabels(['No stroke', 'Stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Important Features\n",
    "TODO: Hvad betyder det her? skal det med, eller udelades? I så fald forklar hvad det viser\n",
    "\n",
    "*Soure:*\n",
    "https://machinelearningmastery.com/rfe-feature-selection-in-python/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying feature_importances_ on the classification tree\n",
    "dtree_imp = list(dtree_tuned.feature_importances_)\n",
    "\n",
    "# Get column names\n",
    "dtree_colname = list(X_train.columns)\n",
    "\n",
    "# Making a dict for dataframe\n",
    "dtree_dict = {'Feature':dtree_colname,'Importance':dtree_imp}\n",
    "\n",
    "# Creating a dataframe with the feature importance values\n",
    "dtree_feature_imp = pd.DataFrame(dtree_dict)\n",
    "\n",
    "# Ranking the features according to feature importance values\n",
    "dtree_feature_rank = dtree_feature_imp.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print top N features\n",
    "dtree_feature_rank.head(20)\n",
    "\n",
    "# source: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting top 10 feature importances of the classification tree\n",
    "feature_importances = pd.Series(dtree_tuned.feature_importances_, index=X.columns)\n",
    "feature_importances.nlargest(10).plot(kind='barh')\n",
    "plt.title(\"Top 10 Important Features - without SMOTE\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying feature_importances_ on the classification tree\n",
    "dtree_imp_res = list(dtree_tuned_res.feature_importances_)\n",
    "\n",
    "dtree_colname_res = list(X_train_res.columns)\n",
    "\n",
    "#Create dict for datafram\n",
    "dtree_dict_res = {'Feature':dtree_colname_res,'Importance':dtree_imp_res}\n",
    "\n",
    "# Creating a dataframe with the feature importance values\n",
    "dtree_feature_imp_res = pd.DataFrame(dtree_dict_res)\n",
    "\n",
    "# Ranking the features according to feature importance values\n",
    "dtree_feature_rank_res = dtree_feature_imp_res.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print top N features\n",
    "dtree_feature_rank_res.head(20)\n",
    "\n",
    "# source: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_\n",
    "# Somethings wrong with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting top 10 feature importances of the classification tree  - WITH SMOTE\n",
    "feature_importances_res = pd.Series(dtree_tuned_res.feature_importances_, index=X_res.columns)\n",
    "feature_importances_res.nlargest(10).plot(kind='barh')\n",
    "plt.title(\"Top 10 Important Features - with SMOTE\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RFECV\n",
    "Dette afsnit er kun for test af hvordan man kan bruge RFECV til at finde important features. \n",
    "Brugt fra:\n",
    "-  https://practicaldatascience.co.uk/machine-learning/how-to-use-recursive-feature-elimination-in-your-models\n",
    "- Simones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RFECV to identify most important features in regard to recall\n",
    "\n",
    "# Defining the selector\n",
    "dtree_rfecv = RFECV(estimator=dtree_tuned, \n",
    "              step=1, \n",
    "              cv=StratifiedKFold(6), # Cross-validation for evaluation model\n",
    "              scoring='recall')\n",
    "\n",
    "# Fitting selector to training set\n",
    "dtree_rfecv.fit(X_train, y_train)\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Decision Tree - RFECV (wo.SMOTE)', fontsize=16, pad=16)\n",
    "plt.xlabel('Number of features selected', fontsize=12, labelpad=16)\n",
    "plt.ylabel('% Correct Classification', fontsize=12, labelpad=16)\n",
    "plt.plot(range(1, len(dtree_rfecv.cv_results_['mean_test_score']) + 1), dtree_rfecv.cv_results_['mean_test_score'], linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance - after applying RFECV\n",
    "dtree_rfecv_imp = dtree_rfecv.estimator_.feature_importances_\n",
    "\n",
    "# Creating new X\n",
    "X_copy = X_train.copy()\n",
    "X_imp = X_copy.drop(X_copy.columns[np.where(dtree_rfecv.support_ == False)[0]], axis=1, inplace=True)\n",
    "\n",
    "# Getting column names\n",
    "dtree_rcefv_colname = list(X_copy.columns)\n",
    "\n",
    "# Creating dict for dataframe\n",
    "rfecv_dict = {'Feature':dtree_rcefv_colname,'Importance':dtree_rfecv_imp}\n",
    "\n",
    "# Create dataframe\n",
    "dtree_rfecv_feature_imp = pd.DataFrame(rfecv_dict).sort_values(by='Importance',ascending = False)\n",
    "\n",
    "# Print\n",
    "dtree_rfecv_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing results\n",
    "print('Optimal amount of features:',dtree_rfecv.n_features_)\n",
    "\n",
    "# Name of the optimal features listed by the RFECV\n",
    "print('Selected features:', list(X_train.columns[dtree_rfecv.support_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features that have been removed:', list(X.columns[dtree_rfecv.support_] ^ X.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RFECV to identify most important features in regard to recall\n",
    "\n",
    "# Defining the selector\n",
    "dtree_rfecv_res = RFECV(estimator=dtree_tuned_res, \n",
    "              step=1, \n",
    "              cv=StratifiedKFold(6), # Cross-validation for evaluation model\n",
    "              scoring='recall')\n",
    "\n",
    "# Fitting selector to training set\n",
    "dtree_rfecv_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Decision Tree - RFECV (w.SMOTE)', fontsize=16, pad=16)\n",
    "plt.xlabel('Number of features selected', fontsize=12, labelpad=16)\n",
    "plt.ylabel('% Correct Classification', fontsize=12, labelpad=16)\n",
    "plt.plot(range(1, len(dtree_rfecv_res.cv_results_['mean_test_score']) + 1), dtree_rfecv_res.cv_results_['mean_test_score'], linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance - after applying RFECV\n",
    "dtree_rfecv_imp_res = dtree_rfecv_res.estimator_.feature_importances_\n",
    "\n",
    "# Creating new X\n",
    "X_copy = X_train.copy()\n",
    "X_imp_res = X_copy.drop(X_copy.columns[np.where(dtree_rfecv_res.support_ == False)[0]], axis=1, inplace=True)\n",
    "\n",
    "# Getting column names\n",
    "dtree_colname = list(X_copy.columns)\n",
    "\n",
    "# Creating dict for dataframe\n",
    "dtree_rfecv_dict_res = {'Feature':dtree_colname,'Importance':dtree_rfecv_imp_res}\n",
    "\n",
    "#Create dataframe\n",
    "rfecv_feature_imp_res = pd.DataFrame(dtree_rfecv_dict_res).sort_values(by='Importance',ascending = False)\n",
    "# Print\n",
    "rfecv_feature_imp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing results\n",
    "print('Optimal amount of features:',dtree_rfecv_res.n_features_)\n",
    "\n",
    "# Name of the optimal features listed by the RFECV\n",
    "print('Selected features:', list(X_res.columns[dtree_rfecv_res.support_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features that have been removed:', list(X_res.columns[dtree_rfecv_res.support_] ^ X_res.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning model\n",
    "\n",
    "- Optimized hyperparameters\n",
    "- Selected important features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the tuned model to predict y using test set\n",
    "y_dtree_pred = dtree_rfecv.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the tuned model to predict y using test set\n",
    "y_dtree_pred_res = dtree_rfecv_res.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting scores\n",
    "\n",
    "We will now compute the scores of the predicted values to evaluate how well the tuned model is classifying new cases.\n",
    "\n",
    "*Source:* https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing scores on training and testing set\n",
    "print(\"---------- Without SMOTE ----------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dtree_tuned.score(X_train, y_train)))\n",
    "print(\"Accuracy on testing set: {:.3f}\".format(dtree_tuned.score(X_test, y_test)))\n",
    "print('Precision-score: %.3f' % precision_score(y_test, y_dtree_pred))\n",
    "print('Recall-score: %.3f' % recall_score(y_test, y_dtree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report after tuning hyperparameters\n",
    "print(classification_report(y_test,y_dtree_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting confusion matrix using actual y_test and predicted y_test data sets \n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        y_dtree_pred\n",
    "    ),\n",
    "    annot=True,\n",
    "    fmt = \"d\",\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"CONFUSION MATRIX: Classification Tree - Tuned (wo. SMOTE)\",fontsize=14)\n",
    "ax.xaxis.set_ticklabels(['No stroke', 'Stroke']); \n",
    "ax.yaxis.set_ticklabels(['No stroke', 'Stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing scores on training and testing set\n",
    "print(\"---------- With SMOTE ----------\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dtree_tuned_res.score(X_train_res, y_train_res)))\n",
    "print(\"Accuracy on testing set: {:.3f}\".format(dtree_tuned_res.score(X_test, y_test)))\n",
    "print('Precision-score: %.3f' % precision_score(y_test, y_dtree_pred_res))\n",
    "print('Recall-score: %.3f' % recall_score(y_test, y_dtree_pred_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report after tuning hyperparameters\n",
    "print(classification_report(y_test,y_dtree_pred_res, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottting confusion matrix using actual y_test and predicted y_test data sets \n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        y_dtree_pred_res\n",
    "    ),\n",
    "    annot=True,\n",
    "    fmt = \"d\",\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"CONFUSION MATRIX: Classification Tree - Tuned (w. SMOTE)\",fontsize=14)\n",
    "ax.xaxis.set_ticklabels(['No stroke', 'Stroke']); \n",
    "ax.yaxis.set_ticklabels(['No stroke', 'Stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- TODO: Hvorfor bliver precision og recall score 0? - TJEK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of tuned classification trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the new tuned, pruned trees like we did above\n",
    "plt.figure(figsize=(15,15))  # set plot size (denoted in inches)\n",
    "tree.plot_tree(dtree_tuned, fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the new tuned, pruned tree\n",
    "plt.figure(figsize=(15,15))  # set plot size (denoted in inches)\n",
    "tree.plot_tree(dtree_tuned_res, fontsize=7)\n",
    "# plt.savefig('Classification Tree with SMOTE.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Se på følgende:\n",
    "\n",
    "**Randomness vs. control**\n",
    "https://towardsdatascience.com/harnessing-randomness-in-machine-learning-59e26e82fdfc\n",
    "\n",
    "**Baseline models**\n",
    "https://towardsai.net/p/l/what-are-baseline-models-and-benchmarking-for-machine-learning-why-we-need-them?amp=1\n",
    "\n",
    "**Feature importance / feature selection**\n",
    "- Session 5: Lasso\n",
    "- Mutual information\n",
    "- Gini imuprity\n",
    "- wrapper feature selection method. rfe\n",
    "- https://towardsdatascience.com/understanding-feature-importance-and-how-to-implement-it-in-python-ff0287b20285\n",
    "\n",
    "- Feature selection > Lige indnen træning af data \n",
    "https://www.datacamp.com/tutorial/feature-selection-python\n",
    "\n",
    "\n",
    "- Rækkefølge af data prepro\n",
    "https://stats.stackexchange.com/questions/440372/feature-selection-before-or-after-encoding\n",
    "\n",
    "- SMOTE efter feature selection https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3648438/\n",
    "\n",
    "Cross validation:\n",
    "- Useful for cases where you have small datasets and you need to utilize every little bit of information to develop your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7 (default, Sep  3 2021, 12:45:31) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
